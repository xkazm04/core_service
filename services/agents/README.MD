
# Agent state


# Workflow explained

## A. Question workflow - complete

User writes a request in chat window from React application in form of free text message without given structure. To achieve completion of user's task **we DO know enough information**

Request is delivered via REST API
- `user_id` 
- `message` - Chat messaged typed by user in React app
- `type` - Topic of the request, by default `general`, but specifiyng `character` or `story` could in some cases increase agent precision. *Will be descoped*
- `project_id` - Key identificator to gather all necessary project data
- `character_id` - Optional identificator to operate upon specific character
- `act_id` - Optional identificator to operate upon specific story act
- `chat_session_id` - Uuid generated by the frontend. Used for keeping memory inside only one conversation.
- `be_function` - If user chooses predefined operations, this attributes starts db actions without further questions
- `function_params` - Free dictionary with parameters necessary to handle db actions

1. **User interface**
- Agent parses **ChatRequest** into parameters needed for further decisions in route `agent.py` and starts LangGraph workflow


2. **Character name extraction**
The workflow starts with character name extraction via pre-processor `name_extraction.py`
TBD migrate to preprocessors
3. **Function pre-processing** 
- `intent_deteciton.py`: Identification of the use case and tool to use based on that. Most tools are connected to internal db tables. Intent defines which table and data to use
in function `extract_operation_intent`.

- `detect_operation_intent` helps recognize category of the use case, if not specifically provided by user request to agent state via param `type`
4. **Tool calling**
- The agent processes messages in `call_model_for_tool_or_direct`
- It uses tools via `tool_node_executor`

6. **Suggestions**
Operations are executed through `execute_suggestion_function`

The agent has prompts to detect execution opportunities through the `execution_detection_message` in `graph_nodes.py`.

- `get_suggestions_from_topic`
7. **Response**
- `generate_final_response` - Response node 
TBD db param

---
## B. Question workflow - Incomplete
1. **User interface**
User writes a request in chat window from React application in form of free text message without given structure. To achieve completion of user's task **we DO NOT know enough information** and need to ask for further detail
- Request is delivered via REST API
TBD structure of the request

2. **Intent detection**
`extract_operation_intent`: Detects `operation_intent='character_create'`, `params={}`, `missing_params=['target_char_name']`. These are stored in `AgentState`.
3. **Executor map**
Workflow finds instructions based on the intent with `call_model_for_tool_or_direct` 
- Finds `operation_intent`.
- Sees `missing_params` is not empty.
- Constructs an AIMessage: "To proceed with `character_create`, I need some more information: `target_char_name`. Could you please provide it?"
- Returns this `message`. `operation_intent`, `operation_params`, and `missing_params` remain in the state.
4. **Tool decision - negative**
In this case there is no tool to call in `should_continue_or_finalize`, so it routes to finalize. The agent asks the user the question to specify name further
5. **User input #2**
User provides again information necessary and points above are retun in the same order, this time with extracter `target_char_name`
6. **Tool decision - positive**
- Finds a tool to execute database function for character POST. Success is then responded to the user
TBD - map response schema

---



# TO DO

## A. Features & Robustness:

**Advanced Error Recovery:** 
Expand tool error handling in tool_node_executor. The current recovery_message is a good start; consider more specific recovery strategies based on error types from tools.

## B. Design & Architecture:

**Refactor** 
call_model_for_tool_or_direct: This function in graph_nodes.py is complex. Consider breaking it into smaller, more focused functions or even sub-graphs within LangGraph to handle distinct states (awaiting confirmation, missing params, etc.) for better readability and maintainability.

**Configuration Management** 
Move CONFIRMATION_REQUIRED_OPERATIONS from a hardcoded set in graph_nodes.py to a configuration file or a more dynamic system, especially if this list is expected to grow.

**Memory Strategy for Long Conversations**
While MemorySaver is used, for very long conversations, implement strategies like conversation summarization or windowing to manage context length for LLMs and control costs. The truncate_problematic_history function is a good first step.

## C. Code Quality & Maintainability:

**Prompt Management**
Centralize and manage LLM prompts (currently embedded in various Python files like intent_detection.py and graph_nodes.py). Use a templating library or store them in dedicated files (like improvement_temps.py or agno_templates.py seem to hint at) for easier versioning and iteration.

**Comprehensive Testing** 
Implement unit and integration tests for graph nodes, conditional logic functions (like should_continue_or_finalize), preprocessors, and executors to ensure reliability and catch regressions.

**Input Sanitization/Validation** 
Rigorously validate and sanitize all inputs derived from user messages that are used in database queries or become part of LLM prompts to prevent security vulnerabilities (e.g., SQL injection, prompt injection). This is especially important for parameters passed to execute_suggestion_function and those embedded in LLM prompts.
